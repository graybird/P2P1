package com.neurogrid.simulation;

import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.Properties;
import java.util.Random;
import java.util.Set;
import java.util.Vector;

import org.apache.log4j.BasicConfigurator;
import org.apache.log4j.Category;
import org.apache.log4j.PropertyConfigurator;

import junit.framework.TestCase;
import junit.framework.TestSuite;

import com.neurogrid.simulation.root.ContentMessage;
import com.neurogrid.simulation.root.Document;
import com.neurogrid.simulation.root.Keyword;
import com.neurogrid.simulation.root.NetworkParameters;
import com.neurogrid.simulation.root.Node;
import com.neurogrid.simulation.statistics.SearchStatistics;
// JUnitDoclet end import

/**
* Generated by JUnitDoclet, a tool provided by
* ObjectFab GmbH under LGPL.
* Please see www.junitdoclet.org, www.gnu.org
* and www.objectfab.de for informations about
* the tool, the licence and the authors.
*/

public class AdversarialNetworkTest
// JUnitDoclet begin extends_implements
extends TestCase
// JUnitDoclet end extends_implements
{
	private static Category o_cat =
		Category.getInstance(NeuroGridNode.class.getName());

	/**
	 * initialize the logging system
	 *
	 * @param p_conf      configuration filename
	 */
	public static void init(String p_conf)
	{
		BasicConfigurator.configure();
		PropertyConfigurator.configure(p_conf);
		o_cat.info("NeuroGridNode logging Initialized");
	}

	// JUnitDoclet begin class
	com.neurogrid.simulation.AdversarialNetwork adversarialnetwork = null;

	// JUnitDoclet end class

	/**
	* @param name  - the test name
	*/
	public AdversarialNetworkTest(String name)
	{
		super(name);
		AdversarialNetwork.init(System.getProperty("Log4jConfig"));
	}

	/**
	 * @return an instance of an adversarial network
	 * @throws Exception an exception creating the adversarial network
	 */
	public com.neurogrid.simulation.AdversarialNetwork createInstance()
		throws Exception
	{
		// JUnitDoclet begin method testcase.createInstance
		return new com.neurogrid.simulation.AdversarialNetwork();
		// JUnitDoclet end method testcase.createInstance
	}

	/**
	 * @see junit.framework.TestCase#setUp()
	 */
	protected void setUp() throws Exception
	{
		// JUnitDoclet begin method testcase.setUp
		super.setUp();
		adversarialnetwork = createInstance();
		// JUnitDoclet end method testcase.setUp
	}

	/**
	 * @see junit.framework.TestCase#tearDown()
	 */
	protected void tearDown() throws Exception
	{
		// JUnitDoclet begin method testcase.tearDown
		adversarialnetwork = null;
		super.tearDown();
		// JUnitDoclet end method testcase.tearDown
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGetCvsInfo() throws Exception
	{
		// JUnitDoclet begin method getCvsInfo
		// JUnitDoclet end method getCvsInfo
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testInit() throws Exception
	{
		// JUnitDoclet begin method init
		// JUnitDoclet end method init
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testClearNetwork() throws Exception
	{
		// JUnitDoclet begin method clearNetwork
		// JUnitDoclet end method clearNetwork
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testRefresh() throws Exception
	{
		// JUnitDoclet begin method refresh
		// JUnitDoclet end method refresh
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGetNetworkID() throws Exception
	{
		// JUnitDoclet begin method getNetworkID
		// JUnitDoclet end method getNetworkID
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testToString() throws Exception
	{
		// JUnitDoclet begin method toString
		// JUnitDoclet end method toString
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testAddNodes() throws Exception
	{
		// JUnitDoclet begin method addNodes
		// JUnitDoclet end method addNodes
	}

	public static final int RANDOM_SEED = 888;

	/**
	 * @throws Exception a general exception
	 */
	public void testCreateNodes() throws Exception
	{
		final int NO_NODES = 5;

		HashMap x_nodes =
			adversarialnetwork.createNodes(
				NO_NODES,
				NO_NODES,
				new Random(RANDOM_SEED));
		assertTrue("5 nodes not created", x_nodes.size() == NO_NODES);
		Iterator x_iter = x_nodes.values().iterator();
		String x_temp = null;
		while (x_iter.hasNext())
		{
			x_temp = (x_iter.next().getClass()).getName();
			//System.out.println(x_temp);
			assertTrue(
				"not gnutella nodes",
				x_temp.equals("com.neurogrid.simulation.AdversarialNode"));
		}

		// I'm conflicted about whether nodes should be in the network
		// or stay as static items in the Node class ....?

		//assertTrue("static table doesn't have 5 nodes",Node.o_nodes.size()==5);
		// JUnitDoclet end method createNodes
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testCreateKeywords() throws Exception
	{
		final int NO_NODES = 5;

		HashMap x_keywords = adversarialnetwork.createKeywords(NO_NODES);
		assertTrue("5 keywords not created", x_keywords.size() == NO_NODES);
		Iterator x_iter = x_keywords.values().iterator();
		String x_temp = null;
		while (x_iter.hasNext())
		{
			x_temp = (x_iter.next().getClass()).getName();
			//System.out.println(x_temp);
			assertTrue(
				"not simple Keywords",
				x_temp.equals("com.neurogrid.simulation.SimpleKeyword"));
		}

		// I'm conflicted about whether keywords should be in the network
		// or stay as static items in the Keyword class ....?

		//assertTrue("static table doesn't have 5 keywords",Keyword.o_keywords.size()==5);
		// should we be clearing the network each time ???? FIXXXXXXXX
		// JUnitDoclet end method createKeywords
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testCreateNetwork() throws Exception
	{
		final int NO_NODES = 10;

		// creating the network involves
		// 1. making some nodes
		// 2. making some keywords and documents
		// 3. placing some of this content in the nodes
		// 4. generating connections
		// 5. (optional) generate knowledge .... don't need this for gnutella

		Properties x_properties = new Properties();

		x_properties.setProperty(
			NetworkParameters.SIMULATION_TYPE,
			"Adversarial");
		x_properties.setProperty(NetworkParameters.NO_KEYWORDS, "10");
		x_properties.setProperty(NetworkParameters.NO_DOCUMENTS, "10");
		x_properties.setProperty(
			NetworkParameters.NO_KEYWORDS_PER_DOCUMENT,
			"2");
		x_properties.setProperty(
			NetworkParameters.NO_NODES,
			Integer.toString(NO_NODES));
		x_properties.setProperty(
			NetworkParameters.NO_HONEST_NODES,
			Integer.toString(NO_NODES));
		x_properties.setProperty(NetworkParameters.NO_DOCUMENTS_PER_NODE, "2");
		//x_properties.setProperty(NetworkParameters.MAX_KNOWLEDGE_PER_NODE,"2");
		x_properties.setProperty(
			NetworkParameters.NO_CONNECTIONS_PER_NODE,
			"2");
		x_properties.setProperty(
			NetworkParameters.MAX_CONNECTIONS_PER_NODE,
			"2");
		x_properties.setProperty(NetworkParameters.START_TTL, "7");
		//x_properties.setProperty(NetworkParameters.DEGREE_OF_CORRELATION,"1");
		//x_properties.setProperty(NetworkParameters.FORWARDING_MODEL,"0");
		x_properties.setProperty(NetworkParameters.INTERNAL_LOOP, "100");
		x_properties.setProperty(NetworkParameters.PROBE_LOOP, "100");
		x_properties.setProperty(NetworkParameters.NO_PROBES, "0");
		x_properties.setProperty(NetworkParameters.GROWTH_LOOP, "100");
		x_properties.setProperty(NetworkParameters.STATS_LOOP, "10");
		//x_properties.setProperty(NetworkParameters.KNOWLEDGE,"false");
		//x_properties.setProperty(NetworkParameters.LEARNING,"false");
		x_properties.setProperty(NetworkParameters.RING_TOPOLOGY, "true");
		x_properties.setProperty(
			NetworkParameters.DOC_KEYWORD_ZIPF_DISTRIBUTION,
			"false");
		x_properties.setProperty(
			NetworkParameters.NODE_DOC_ZIPF_DISTRIBUTION,
			"false");
		x_properties.setProperty(NetworkParameters.RANDOM_SEARCHES, "true");
		x_properties.setProperty(NetworkParameters.RANDOM_FORWARDING, "true");
		x_properties.setProperty(NetworkParameters.APPLET, "false");

		// really we need a series of Network Parameters because not all parameters
		// are relevant for all simulations - could have GnutellaParameters etc.

		//FileInputStream x_input = new FileInputStream("./conf/GNUTELLA.properties");
		//o_properties.load(x_input);
		//x_input.close();

		NetworkParameters x_network_parameters = new NetworkParameters();
		x_network_parameters.parse(x_properties);

		adversarialnetwork.createNetwork(x_network_parameters, new Random());

		assertTrue(
			"Network has incorrect number of nodes",
			adversarialnetwork.getNoNodes() == NO_NODES);

		// now we need to assess the network/documents etc...
		// feels like testing would be much easier if all the different objects where associated 
		// with the network and got created from scratch each time, and any accessing of these
		// objects came through queries on the network itself ...

		// so next step would be to modify createNetwork and then run a complete test of that
		// before moving on to search network and associated test ....
		// JUnitDoclet end method createNetwork
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testCreateKeywordsAndDocuments() throws Exception
	{
		// JUnitDoclet begin method createKeywordsAndDocuments
		// JUnitDoclet end method createKeywordsAndDocuments
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testSetSendingMessageFalse() throws Exception
	{
		// JUnitDoclet begin method setSendingMessageFalse
		// JUnitDoclet end method setSendingMessageFalse
	}

	public static final int THREE_KEYWORDS = 3;

	/**
	 * @throws Exception a general exception
	 */
	public void testHasKeyword() throws Exception
	{
		// JUnitDoclet begin method setSendingMessageFalse

		// need to create documents with specific keywords and add them to 
		// the network
		try
		{
			adversarialnetwork.hasKeyword(null);
			fail("Failed to throw exception when checking for null content");
		}
		catch (Exception e)
		{
			o_cat.debug(e);
		}

		Keyword[] x_keywords = new SimpleKeyword[THREE_KEYWORDS];
		Keyword[] x_keywords2 = new SimpleKeyword[THREE_KEYWORDS];

		for (int i = 0; i < THREE_KEYWORDS; i++)
		{
			x_keywords[i] = new SimpleKeyword();
			x_keywords2[i] = new SimpleKeyword();
		}

		SimpleDocument x_doc = new SimpleDocument(x_keywords);
		SimpleDocument x_doc2 = new SimpleDocument(x_keywords2);

		AdversarialNode x_node =
			new AdversarialNode(
				adversarialnetwork,
				new GnutellaMessageHandler(new Random(RANDOM_SEED)));

		x_node.addContent(x_doc);

		for (int i = 0; i < THREE_KEYWORDS; i++)
		{
			assertTrue(
				"local keyword not indicated",
				adversarialnetwork.hasKeyword(x_keywords[i]) == 1);
			assertTrue(
				"absent keyword identified as local",
				adversarialnetwork.hasKeyword(x_keywords2[i]) == 0);
		}
		// JUnitDoclet end method setSendingMessageFalse
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGetRandomSearchKeywords() throws Exception
	{
		// JUnitDoclet begin method getRandomSearchKeywords
		final int NO_KEYWORDS = 5;
		final int NO_NODES = 10;

		HashMap x_keys = adversarialnetwork.createKeywords(NO_KEYWORDS);
		final int NO_DOCS = 10;
		final int NO_KEYWORDS_PER_DOC = 3;
		final int SEED = 999;
		Random x_random = new Random(SEED);

		HashMap x_docs =
			adversarialnetwork.createDocuments(
				NO_DOCS,
				NO_KEYWORDS_PER_DOC,
				false,
				x_random);

		HashMap x_nodes =
			adversarialnetwork.createNodes(
				NO_NODES,
				NO_NODES,
				new Random(RANDOM_SEED));
		adversarialnetwork.generateContent(
			x_nodes,
			x_docs,
			x_docs,
			NO_KEYWORDS_PER_DOC,
			false,
			x_random);

		Iterator x_node_iter = x_nodes.values().iterator();

		Keyword[] x_keywords = null;
		final int DIFF_NO_KEYWORDS = 3;
		Node x_node = null;

		// not sure if there is an effective way to test that 
		// the different picks really are random ......

		while (x_node_iter.hasNext())
		{
			x_node = (Node) (x_node_iter.next());
			x_keywords =
				adversarialnetwork.getRandomSearchKeywords(
					DIFF_NO_KEYWORDS,
					x_random);

			// would like to get keywords that do exist in the network ....
			// and that are associated with the search start location ....

			for (int i = 0; i < DIFF_NO_KEYWORDS; i++)
			{
				System.out.println(x_keywords[i].getKeywordID());
				assertTrue(
					"keyword not in network",
					adversarialnetwork.hasKeyword(x_keywords[i]) > 0);
				assertTrue(
					"keywords not unique",
					x_keywords[i] != x_keywords[(i + 1) % DIFF_NO_KEYWORDS]);
			}

		}

		// would like to get keywords that do exist in the network ....

		// JUnitDoclet end method getRandomSearchKeywords
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGetAssociatedSearchKeywords() throws Exception
	{
		// JUnitDoclet begin method getAssociatedSearchKeywords
		final int x_start_no_keywords = 5;

		adversarialnetwork.createKeywords(x_start_no_keywords);
		final int x_no_docs = 10;
		final int x_no_nodes = 10;
		final int x_no_keywords_per_doc = 3;
		final int SEED = 999;
		Random x_random = new Random(SEED);

		HashMap x_docs =
			adversarialnetwork.createDocuments(
				x_no_docs,
				x_no_keywords_per_doc,
				false,
				x_random);

		HashMap x_nodes =
			adversarialnetwork.createNodes(x_no_nodes, x_no_nodes, x_random);
		adversarialnetwork.generateContent(
			x_nodes,
			x_docs,
			x_docs,
			x_no_keywords_per_doc,
			false,
			x_random);

		Iterator x_node_iter = x_nodes.values().iterator();

		Keyword[] x_keywords = null;
		final int x_no_keywords = 3;
		Node x_node = null;

		// not sure if there is an effective way to test that 
		// the different picks really are random ......

		while (x_node_iter.hasNext())
		{
			x_node = (Node) (x_node_iter.next());
			x_keywords =
				adversarialnetwork.getAssociatedSearchKeywords(
					x_no_keywords,
					x_node,
					x_random);

			// would like to get keywords that do exist in the network ....
			// and that are associated with the search start location ....

			for (int i = 0; i < x_no_keywords; i++)
			{
				//System.out.println(x_keywords[i].getKeywordID());
				assertTrue(
					"keyword not associated with node",
					x_node.hasKeyword(x_keywords[i]) > 0);
				assertTrue(
					"keywords not unique",
					x_keywords[i] != x_keywords[(i + 1) % x_no_keywords]);
			}

		}
		// JUnitDoclet end method getAssociatedSearchKeywords
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGetRandomSearchStart() throws Exception
	{
		// JUnitDoclet begin method getRandomSearchStart
		final int x_no_start_keywords = 5;

		adversarialnetwork.createKeywords(x_no_start_keywords);
		final int x_no_docs = 10;
		final int x_no_nodes = 10;
		final int x_no_keywords_per_doc = 3;
		final int SEED = 999;
		Random x_random = new Random(SEED);

		HashMap x_docs =
			adversarialnetwork.createDocuments(
				x_no_docs,
				x_no_keywords_per_doc,
				false,
				x_random);
		Iterator x_doc_iter = x_docs.values().iterator();

		HashMap x_nodes =
			adversarialnetwork.createNodes(x_no_nodes, x_no_nodes, x_random);
		adversarialnetwork.generateContent(
			x_nodes,
			x_docs,
			x_docs,
			x_no_keywords_per_doc,
			false,
			x_random);

		Vector x_vec = Node.getVectorFromMap(x_nodes);
		//adversarialnetwork.generateRandomTopology(x_vec,x_vec,2,true);
		Node x_node = null;
		Document x_doc = null;
		while (x_doc_iter.hasNext())
		{
			x_doc = (Document) (x_doc_iter.next());
			x_node = adversarialnetwork.getRandomSearchStart(x_doc, x_random);
			assertTrue(
				"selected node "
					+ x_node.getNodeID()
					+ " failed to claim contains target document",
				x_node.hasContent(x_doc));
		}

		// JUnitDoclet end method getRandomSearchStart
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGetAssociatedSearchTarget() throws Exception
	{
		// JUnitDoclet begin method getAssociatedSearchTarget
		final int x_start_no_keywords = 5;

		adversarialnetwork.createKeywords(x_start_no_keywords);
		final int x_no_docs = 10;
		final int x_no_nodes = 10;
		final int x_no_keywords_per_doc = 3;
		final int SEED = 999;
		Random x_random = new Random(SEED);

		HashMap x_docs =
			adversarialnetwork.createDocuments(
				x_no_docs,
				x_no_keywords_per_doc,
				false,
				x_random);

		HashMap x_nodes =
			adversarialnetwork.createNodes(x_no_nodes, x_no_nodes, x_random);
		Iterator x_node_iter = x_nodes.values().iterator();

		adversarialnetwork.generateContent(
			x_nodes,
			x_docs,
			x_docs,
			x_no_keywords_per_doc,
			false,
			x_random);

		Vector x_vec = Node.getVectorFromMap(x_nodes);
		//adversarialnetwork.generateRandomTopology(x_vec,x_vec,2,true);
		Node x_node = null;
		Document x_doc = null;
		int x_sum = 0;
		while (x_node_iter.hasNext())
		{
			x_node = (Node) (x_node_iter.next());
			x_doc =
				adversarialnetwork.getAssociatedSearchTarget(x_node, x_random);
			assertTrue("returned document is null", x_doc != null);
			// maybe doc is allowed to be null
			assertTrue(
				"selected node "
					+ x_node.getNodeID()
					+ " contains target document",
				!x_node.hasContent(x_doc));
			// should check that search target does share a keyword in common with the contents of the local node 
			x_sum = 0;
			for (int i = 0; i < x_no_keywords_per_doc; i++)
			{
				if (x_node.hasKeyword(x_doc.getKeywords()[i]) >= 1)
				{
					x_sum++;
				}
				assertTrue(
					"no associated keywords claimed when they should bein start location",
					x_sum == 0);
				// this will fail sometimes - would need some work for additional checking
			}
		}

		// JUnitDoclet end method getAssociatedSearchTarget
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testFuzzySearchNetwork() throws Exception
	{
		final int x_start_no_keywords = 10;

		HashMap x_keywords =
			adversarialnetwork.createKeywords(x_start_no_keywords);
		final int x_no_docs = 5;
		final int x_no_nodes = 5;
		final int x_no_keywords_per_doc = 3;
		final int SEED = 999;

		// feels like we should be specifying the type of distribution through an argument rather than
		// a global variable
		// also feels like we should be handing back a set of documents to check ....

		HashMap x_docs =
			adversarialnetwork.createDocuments(
				x_no_docs,
				x_no_keywords_per_doc,
				false,
				new Random(SEED));
		Iterator x_doc_iter = x_docs.values().iterator();

		HashMap x_nodes =
			adversarialnetwork.createNodes(
				x_no_nodes,
				x_no_nodes,
				new Random(SEED));
		Iterator x_node_iter = x_nodes.values().iterator();
		adversarialnetwork.generateContent(
			x_nodes,
			x_docs,
			x_docs,
			x_no_keywords_per_doc,
			false,
			new Random(SEED));
		// feels like generate content should take Documents as an argument ...
		// issue is that we can have several different distributions of documents
		// i.e. they are not associated with the network in the way that nodes are
		// one could imagine a DocumentCollection? Corpus? class that would represent
		// a set of documents/files ....
		Vector x_vec = Node.getVectorFromMap(x_nodes);
		adversarialnetwork.generateRingTopology(x_vec, 2);

		SearchStatistics x_search_stats = null;
		Document x_doc = null;
		Node x_node = null;
		final int x_TTL = 5;
		final int x_no_params = 6;
		final int[] x_stats = new int[x_no_params];
		x_stats[ACTIVATED_NODES] = 0;
		x_stats[POSSIBLE_TARGETS] = 0;
		x_stats[MESSAGE_TRANSFERS] = 0;
		x_stats[TTL_FIRST_MATCH] = -1;
		x_stats[NO_MATCHES] = 0;
		x_stats[NO_FALSE_MATCHES] = 0;
		HashSet x_checked_nodes = new HashSet();
		HashSet x_possible_targets = new HashSet();
		LinkedList x_unchecked_nodes = new LinkedList();
		ContentMessage x_message = null;

		Keyword[] x_keys =
			adversarialnetwork.getRandomSearchKeywords(
				x_no_keywords_per_doc,
				new Random(SEED));

		//while(x_iter.hasNext())    
		//{
		x_doc = (Document) x_doc_iter.next();
		x_node = (Node) x_node_iter.next();
		x_message = new FuzzyContentMessage(x_TTL, x_keys, x_node);

		x_search_stats = adversarialnetwork.searchNetwork(x_message);

		// seems to require me to have a store of which items to search
		// but also to associate some flag with each of them to indicate 
		// whether something was discovered above it in the search tree                                              

		System.out.println("starting node: " + x_node.getNodeID());

		checkFuzzyNode(
			new SearchHolder(
				x_node,
				x_node,
				null,
				x_keys,
				0,
				x_TTL,
				x_stats,
				x_checked_nodes,
				x_possible_targets,
				false,
				x_unchecked_nodes));

		SearchHolder x_holder = null;

		do
		{
			x_holder = (SearchHolder) (x_unchecked_nodes.removeLast());

			System.out.println(
				"x_unchecked_nodes.size(): " + x_unchecked_nodes.size());
			System.out.println("x_node: " + x_holder.o_node.getNodeID());

			checkFuzzyNode(x_holder);

		}
		while (x_unchecked_nodes.size() > 0);

		System.out.println(
			"x_stats[ACTIVATED_NODES]: " + x_stats[ACTIVATED_NODES]);
		System.out.println(
			"x_stats[POSSIBLE_TARGETS]: " + x_stats[POSSIBLE_TARGETS]);
		System.out.println(
			"x_stats[MESSAGE_TRANSFERS]: " + x_stats[MESSAGE_TRANSFERS]);
		System.out.println(
			"x_stats[TTL_FIRST_MATCH]: " + x_stats[TTL_FIRST_MATCH]);
		System.out.println("x_stats[NO_MATCHES]: " + x_stats[NO_MATCHES]);
		System.out.println(
			"x_stats[NO_FALSE_MATCHES]: " + x_stats[NO_FALSE_MATCHES]);

		assertTrue(
			"No. activated nodes incorrect",
			x_search_stats.getNoActivatedNodes() == x_stats[ACTIVATED_NODES]);
		assertTrue(
			"No. possible targets incorrect",
			x_search_stats.getNoPossibleTargets() == x_stats[POSSIBLE_TARGETS]);
		assertTrue(
			"No. message transfers incorrect",
			x_search_stats.getNoMessageTransfers()
				== x_stats[MESSAGE_TRANSFERS]);
		assertTrue(
			"first match ttl incorrect",
			x_search_stats.getTTLOfFirstMatch() == x_stats[TTL_FIRST_MATCH]);
		assertTrue(
			"No. matches incorrect",
			x_search_stats.getNoMatches() == x_stats[NO_MATCHES]);
		assertTrue(
			"No. false matches incorrect",
			x_search_stats.getNoFalseMatches() == x_stats[NO_FALSE_MATCHES]);

		// makes more sense to do refresh test here ...

		adversarialnetwork.refresh();

		x_message = new FuzzyContentMessage(x_TTL, x_keys, x_node);
		SearchStatistics x_search_stats2 =
			adversarialnetwork.searchNetwork(x_message);

		// would love to check how many objects we were increasing by after each loop

		assertTrue(
			"post-refresh: No. activated nodes incorrect",
			x_search_stats.getNoActivatedNodes()
				== x_search_stats2.getNoActivatedNodes());
		assertTrue(
			"post-refresh: No. possible targets incorrect",
			x_search_stats.getNoPossibleTargets()
				== x_search_stats2.getNoPossibleTargets());
		assertTrue(
			"post-refresh: No. message transfers incorrect",
			x_search_stats.getNoMessageTransfers()
				== x_search_stats2.getNoMessageTransfers());
		assertTrue(
			"post-refresh: first match ttl incorrect",
			x_search_stats.getTTLOfFirstMatch()
				== x_search_stats2.getTTLOfFirstMatch());
		assertTrue(
			"post-refresh: No. matches incorrect",
			x_search_stats.getNoMatches() == x_search_stats2.getNoMatches());

		// so we should be checking the stats coming back from the search ...
		/*
		x_search_stats.getNoMatches()
		x_search_stats.getTTLOfFirstMatch()
		x_search_stats.getNoMessageTransfers()
		x_search_stats.getNoActivatedNodes()
		x_search_stats.getNoPossibleTargets() */
		//}

		// the question is should I go as far as getting some stats output from the new gnutella net ..?
		// and put them into matlab in preparation, cos I would like to try searching for random keywords
		// and then seeing how many possible matches come back

		// once we've got this working somewhat, the thing will be to make a NeuroGridNetwork
		// or at least something with NeuroGridMessageHandlers

		// then we could create an AdversarialNetwork, which had AdversarialMessageHandlers ....
		//(there should be some kind of comparison between gnutella routing and neurogrid routing, taking place
		// in adversarial networks ....)

		// would be nice to back all of this up to cvs - or even to the linux box ...

		// JUnitDoclet end method searchNetwork
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testSearchNetwork() throws Exception
	{
		final int x_no_start_keywords = 5;

		adversarialnetwork.createKeywords(x_no_start_keywords);
		final int x_no_docs = 5;
		final int x_no_nodes = 5;
		final int x_no_keywords_per_doc = 3;
		final int SEED = 555;

		// feels like we should be specifying the type of distribution through an argument rather than
		// a global variable
		// also feels like we should be handing back a set of documents to check ....

		HashMap x_docs =
			adversarialnetwork.createDocuments(
				x_no_docs,
				x_no_keywords_per_doc,
				false,
				new Random(SEED));
		Iterator x_doc_iter = x_docs.values().iterator();

		HashMap x_nodes =
			adversarialnetwork.createNodes(
				x_no_nodes,
				x_no_nodes,
				new Random(SEED));
		Iterator x_node_iter = x_nodes.values().iterator();
		adversarialnetwork.generateContent(
			x_nodes,
			x_docs,
			x_docs,
			x_no_keywords_per_doc,
			false,
			new Random(SEED));
		// feels like generate content should take Documents as an argument ...
		// issue is that we can have several different distributions of documents
		// i.e. they are not associated with the network in the way that nodes are
		// one could imagine a DocumentCollection? Corpus? class that would represent
		// a set of documents/files ....
		Vector x_vec = Node.getVectorFromMap(x_nodes);
		adversarialnetwork.generateRingTopology(x_vec, 2);

		SearchStatistics x_search_stats = null;
		Document x_doc = null;
		Node x_node = null;
		final int x_TTL = 5;
		final int x_no_params = 6;
		final int[] x_stats = new int[x_no_params];
		x_stats[ACTIVATED_NODES] = 0;
		x_stats[POSSIBLE_TARGETS] = 0;
		x_stats[MESSAGE_TRANSFERS] = 0;
		x_stats[TTL_FIRST_MATCH] = -1;
		x_stats[NO_MATCHES] = 0;
		x_stats[NO_FALSE_MATCHES] = 0;
		HashSet x_checked_nodes = new HashSet();
		HashSet x_possible_targets = new HashSet();
		LinkedList x_unchecked_nodes = new LinkedList();
		ContentMessage x_message = null;

		// need to work out how to turn off most of the logging and loop this
		// FIXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX    

		//while(x_iter.hasNext())    
		//{
		x_doc = (Document) x_doc_iter.next();
		x_node = (Node) x_node_iter.next();
		x_message =
			new SimpleContentMessage(x_TTL, x_doc.getKeywords(), x_doc, x_node);

		x_search_stats = adversarialnetwork.searchNetwork(x_message);

		// seems to require me to have a store of which items to search
		// but also to associate some flag with each of them to indicate 
		// whether something was discovered above it in the search tree                                              

		System.out.println("starting node: " + x_node.getNodeID());

		checkNode(
			new SearchHolder(
				x_node,
				x_node,
				x_doc,
				x_doc.getKeywords(),
				0,
				x_TTL,
				x_stats,
				x_checked_nodes,
				x_possible_targets,
				false,
				x_unchecked_nodes));

		SearchHolder x_holder = null;

		do
		{
			x_holder = (SearchHolder) (x_unchecked_nodes.removeLast());

			System.out.println(
				"x_unchecked_nodes.size(): " + x_unchecked_nodes.size());
			System.out.println("x_node: " + x_holder.o_node.getNodeID());

			checkNode(x_holder);

		}
		while (x_unchecked_nodes.size() > 0);

		System.out.println(
			"x_stats[ACTIVATED_NODES]: " + x_stats[ACTIVATED_NODES]);
		System.out.println(
			"x_stats[POSSIBLE_TARGETS]: " + x_stats[POSSIBLE_TARGETS]);
		System.out.println(
			"x_stats[MESSAGE_TRANSFERS]: " + x_stats[MESSAGE_TRANSFERS]);
		System.out.println(
			"x_stats[TTL_FIRST_MATCH]: " + x_stats[TTL_FIRST_MATCH]);
		System.out.println("x_stats[NO_MATCHES]: " + x_stats[NO_MATCHES]);
		System.out.println(
			"x_stats[NO_FALSE_MATCHES]: " + x_stats[NO_FALSE_MATCHES]);

		assertTrue(
			"No. activated nodes incorrect",
			x_search_stats.getNoActivatedNodes() == x_stats[ACTIVATED_NODES]);
		assertTrue(
			"No. possible targets incorrect",
			x_search_stats.getNoPossibleTargets() == x_stats[POSSIBLE_TARGETS]);
		assertTrue(
			"No. message transfers incorrect",
			x_search_stats.getNoMessageTransfers()
				== x_stats[MESSAGE_TRANSFERS]);
		assertTrue(
			"first match ttl incorrect",
			x_search_stats.getTTLOfFirstMatch() == x_stats[TTL_FIRST_MATCH]);
		assertTrue(
			"No. matches incorrect",
			x_search_stats.getNoMatches() == x_stats[NO_MATCHES]);
		assertTrue(
			"No. false matches incorrect",
			x_search_stats.getNoFalseMatches() == x_stats[NO_FALSE_MATCHES]);

		// makes more sense to do refresh test here ...

		adversarialnetwork.refresh();

		x_message =
			new SimpleContentMessage(x_TTL, x_doc.getKeywords(), x_doc, x_node);

		SearchStatistics x_search_stats2 =
			adversarialnetwork.searchNetwork(x_message);

		// would love to check how many objects we were increasing by after each loop

		assertTrue(
			"post-refresh: No. activated nodes incorrect",
			x_search_stats.getNoActivatedNodes()
				== x_search_stats2.getNoActivatedNodes());
		assertTrue(
			"post-refresh: No. possible targets incorrect",
			x_search_stats.getNoPossibleTargets()
				== x_search_stats2.getNoPossibleTargets());
		assertTrue(
			"post-refresh: No. message transfers incorrect",
			x_search_stats.getNoMessageTransfers()
				== x_search_stats2.getNoMessageTransfers());
		assertTrue(
			"post-refresh: first match ttl incorrect",
			x_search_stats.getTTLOfFirstMatch()
				== x_search_stats2.getTTLOfFirstMatch());
		assertTrue(
			"post-refresh: No. matches incorrect",
			x_search_stats.getNoMatches() == x_search_stats2.getNoMatches());
		assertTrue(
			"post-refresh: No. false matches incorrect",
			x_search_stats.getNoFalseMatches()
				== x_search_stats2.getNoFalseMatches());

		// so we should be checking the stats coming back from the search ...
		/*
		x_search_stats.getNoMatches()
		x_search_stats.getTTLOfFirstMatch()
		x_search_stats.getNoMessageTransfers()
		x_search_stats.getNoActivatedNodes()
		x_search_stats.getNoPossibleTargets() */
		//}

		// the question is should I go as far as getting some stats output from the new gnutella net ..?
		// and put them into matlab in preparation, cos I would like to try searching for random keywords
		// and then seeing how many possible matches come back

		// once we've got this working somewhat, the thing will be to make a NeuroGridNetwork
		// or at least something with NeuroGridMessageHandlers

		// then we could create an AdversarialNetwork, which had AdversarialMessageHandlers ....
		//(there should be some kind of comparison between gnutella routing and neurogrid routing, taking place
		// in adversarial networks ....)

		// would be nice to back all of this up to cvs - or even to the linux box ...

		// JUnitDoclet end method searchNetwork
	}

	/**
	 * @author <a href="mailto:sam@neurogrid.com">Sam Joseph</a>
	 *
	 * This is a class that helps us work out what the search
	 * results should be ...
	 */
	class SearchHolder
	{
		Node o_node = null;
		Node o_transmitter = null;
		Document o_doc = null;
		Keyword[] o_keywords = null;
		int o_depth = -1;
		int o_TTL = -1;
		int[] o_stats = null;
		HashSet o_nodes = null;
		HashSet o_documents = null;
		boolean o_found = false;
		LinkedList o_unchecked_nodes = null;

		/**
		 * @param p_node --
		 * @param p_transmitter --
		 * @param p_doc --
		 * @param p_keywords --
		 * @param p_depth --
		 * @param p_TTL --
		 * @param p_stats --
		 * @param p_nodes --
		 * @param p_documents --
		 * @param p_found --
		 * @param p_unchecked_nodes --
		 */
		SearchHolder(
			Node p_node,
			Node p_transmitter,
			Document p_doc,
			Keyword[] p_keywords,
			int p_depth,
			int p_TTL,
			int[] p_stats,
			HashSet p_nodes,
			HashSet p_documents,
			boolean p_found,
			LinkedList p_unchecked_nodes)
		{
			o_node = p_node;
			o_transmitter = p_transmitter;
			o_doc = p_doc;
			o_keywords = p_keywords;
			o_depth = p_depth;
			o_TTL = p_TTL;
			o_stats = p_stats;
			o_nodes = p_nodes;
			o_documents = p_documents;
			o_found = p_found;
			o_unchecked_nodes = p_unchecked_nodes;
		}

	}

	private static final int ACTIVATED_NODES = 0;
	private static final int POSSIBLE_TARGETS = 1;
	private static final int MESSAGE_TRANSFERS = 2;
	private static final int TTL_FIRST_MATCH = 3;
	private static final int NO_MATCHES = 4;
	private static final int NO_FALSE_MATCHES = 5;

	/**
	 * @param x_holder  a search holder
	 * @throws Exception  a general exception
	 */
	private void checkNode(SearchHolder x_holder) throws Exception
	{
		// check the activation as it spreads out from start node     
		System.out.println("checking node: " + x_holder.o_node.getNodeID());
		System.out.println("x_holder.o_depth: " + x_holder.o_depth);
		System.out.println("x_holder.o_TTL: " + x_holder.o_TTL);
		System.out.println("x_holder.o_found: " + x_holder.o_found);

		if (x_holder.o_depth <= x_holder.o_TTL
			&& x_holder.o_depth != 0) // && x_holder.o_found == false)
		{
			x_holder.o_stats[MESSAGE_TRANSFERS]++;
			// problem here is that gnutella network avoids sending back down connection
			// message received from ....
		}

		if (x_holder.o_nodes.contains(x_holder.o_node))
		{
			return;
		}
		else
		{
			x_holder.o_nodes.add(x_holder.o_node);
		}

		if (x_holder.o_depth < x_holder.o_TTL) // && x_holder.o_found == false)
		{
			assertTrue(
				"Connected node is not active - " + x_holder.o_node.getNodeID(),
				x_holder.o_node.getActive());
		}
		else
		{
			assertTrue(
				"Connected node passed TTL or after discovery is active - "
					+ x_holder.o_node.getNodeID(),
				!x_holder.o_node.getActive());
		}
		if (x_holder.o_node.getActive())
		{
			x_holder.o_stats[ACTIVATED_NODES]++;
		}

		System.out.println(
			"Checking keywords in: " + x_holder.o_node.getNodeID());

		Keyword[] x_keywords = x_holder.o_node.allKeywords();
		for (int k = 0; k < x_keywords.length; k++)
		{
			System.out.println("x_keywords[" + k + "]" + x_keywords[k]);
		}
		System.out.println(
			"x_holder.o_node.matchingKeywords(x_holder.o_keywords): "
				+ x_holder.o_node.matchingKeywords(x_holder.o_keywords));
		System.out.println(
			(x_holder.o_doc == null
				&& x_holder.o_node.matchingKeywords(x_holder.o_keywords) > 0));
		System.out.println(
			x_holder.o_node.matchingKeywords(x_holder.o_keywords) > 0);
		System.out.println(x_holder.o_doc == null);
		for (int k = 0; k < x_holder.o_keywords.length; k++)
		{
			System.out.println(
				"x_keywords[" + k + "]" + x_holder.o_keywords[k]);
		}
		// adversarial node will lie here meaning possible targets value
		// is confused - actual system assesses possible targets via documents
		// knowledge of their location
		if (x_holder.o_node.hasContent(x_holder.o_doc))
			// this is different for fuzzy saerches
		{
			System.out.println(
				"Found target in: " + x_holder.o_node.getNodeID());
			if (x_holder
				.o_node
				.getContentsByDocID()
				.containsKey(x_holder.o_doc.getDocumentID()))
			{
				x_holder.o_stats[POSSIBLE_TARGETS]++;
			} // check the node really does have the document rather then just claiming it

			if (x_holder.o_depth > 0)
				// not sure about this - takes care of no local search at start ...
			{
				if (x_holder.o_depth < x_holder.o_TTL)
					// && x_holder.o_found == false) //remnant from stops when match
				{
					x_holder.o_stats[NO_MATCHES]++;
					if (!x_holder
						.o_node
						.getContentsByDocID()
						.containsKey(x_holder.o_doc.getDocumentID()))
					{
						x_holder.o_stats[NO_FALSE_MATCHES]++;
					} // check if the node really does have the doc to indicate if this is a false match ...
				}

				x_holder.o_found = true;

				if (x_holder.o_stats[TTL_FIRST_MATCH] == -1)
				{
					System.out.println(
						"first match: "
							+ x_holder.o_node.getNodeID()
							+ ", x_holder.o_TTL - x_holder.o_depth = "
							+ (x_holder.o_TTL - x_holder.o_depth));
					x_holder.o_stats[TTL_FIRST_MATCH] =
						x_holder.o_TTL - x_holder.o_depth;
				}
			}
		}
		System.out.println(
			"x_stats[ACTIVATED_NODES]: " + x_holder.o_stats[ACTIVATED_NODES]);
		System.out.println(
			"x_stats[POSSIBLE_TARGETS]: " + x_holder.o_stats[POSSIBLE_TARGETS]);
		System.out.println(
			"x_stats[MESSAGE_TRANSFERS]: "
				+ x_holder.o_stats[MESSAGE_TRANSFERS]);
		System.out.println(
			"x_stats[TTL_FIRST_MATCH]: " + x_holder.o_stats[TTL_FIRST_MATCH]);
		System.out.println(
			"x_stats[NO_MATCHES]: " + x_holder.o_stats[NO_MATCHES]);
		System.out.println(
			"x_stats[NO_FALSE_MATCHES]: " + x_holder.o_stats[NO_FALSE_MATCHES]);

		Node x_conn = null;

		Collection x_coll = x_holder.o_node.getConnList().values();
		x_coll.remove(x_holder.o_transmitter);
		// avoid checking the node we received from ...
		System.out.println("removing: " + x_holder.o_transmitter.getNodeID());

		Iterator x_conn_iter = x_coll.iterator();

		while (x_conn_iter.hasNext())
		{
			x_conn = (Node) (x_conn_iter.next());
			x_holder.o_unchecked_nodes.addFirst(
				new SearchHolder(
					x_conn,
					x_holder.o_node,
					x_holder.o_doc,
					x_holder.o_keywords,
					x_holder.o_depth + 1,
					x_holder.o_TTL,
					x_holder.o_stats,
					x_holder.o_nodes,
					x_holder.o_documents,
					x_holder.o_found,
					x_holder.o_unchecked_nodes));
		}
	}

	/**
	 * @param x_holder  a search holder
	 * @throws Exception a general exception
	 */
	private void checkFuzzyNode(SearchHolder x_holder) throws Exception
	{
		// check the activation as it spreads out from start node     
		System.out.println("checking node: " + x_holder.o_node.getNodeID());
		System.out.println("x_holder.o_depth: " + x_holder.o_depth);
		System.out.println("x_holder.o_TTL: " + x_holder.o_TTL);
		System.out.println("x_holder.o_found: " + x_holder.o_found);

		if (x_holder.o_depth <= x_holder.o_TTL
			&& x_holder.o_depth != 0) // && x_holder.o_found == false )
		{
			x_holder.o_stats[MESSAGE_TRANSFERS]++;
			// problem here is that gnutella network avoids sending back down connection
			// message received from ....
		}

		if (x_holder.o_nodes.contains(x_holder.o_node))
		{
			return;
		}
		else
		{
			x_holder.o_nodes.add(x_holder.o_node);
		}

		if (x_holder.o_depth < x_holder.o_TTL) // && x_holder.o_found == false)
		{
			assertTrue(
				"Connected node is not active - " + x_holder.o_node.getNodeID(),
				x_holder.o_node.getActive());
		}
		else
		{
			assertTrue(
				"Connected node passed TTL or after discovery is active - "
					+ x_holder.o_node.getNodeID(),
				!x_holder.o_node.getActive());
		}
		if (x_holder.o_node.getActive())
		{
			x_holder.o_stats[ACTIVATED_NODES]++;
		}

		System.out.println(
			"Checking keywords in: " + x_holder.o_node.getNodeID());

		Keyword[] x_keywords = x_holder.o_node.allKeywords();
		for (int k = 0; k < x_keywords.length; k++)
		{
			System.out.println("x_keywords[" + k + "]" + x_keywords[k]);
		}
		System.out.println(
			"x_holder.o_node.matchingKeywords(x_holder.o_keywords): "
				+ x_holder.o_node.matchingKeywords(x_holder.o_keywords));
		System.out.println(
			(x_holder.o_doc == null
				&& x_holder.o_node.matchingKeywords(x_holder.o_keywords) > 0));
		System.out.println(
			x_holder.o_node.matchingKeywords(x_holder.o_keywords) > 0);
		System.out.println(x_holder.o_doc == null);
		for (int k = 0; k < x_holder.o_keywords.length; k++)
		{
			System.out.println(
				"x_keywords[" + k + "]" + x_holder.o_keywords[k]);
		}

		//if(x_holder.o_node.matchingKeywords(x_holder.o_keywords)>0) // this is different for fuzzy saerches
		// I think the above is not relevant to an adversarial network ..
		{
			System.out.println(
				"Found target in: " + x_holder.o_node.getNodeID());

			//x_holder.o_possible_targets.addAll(x_holder.o_node.matchingDocuments(x_holder.o_keywords));
			Set x_set = x_holder.o_node.matchingDocuments(x_holder.o_keywords);
			x_holder.o_stats[POSSIBLE_TARGETS] += x_set.size();
			// question of whether items in the start location should be considered possible targets ..
			// FIXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 

			int x_false_matches = 0;

			Iterator x_iter = x_set.iterator();
			Document x_doc = null;
			int x_sum = 0;

			while (x_iter.hasNext())
			{
				x_doc = (Document) (x_iter.next());
				x_sum = 0;
				for (int i = 0; i < x_holder.o_keywords.length; i++)
				{
					if (x_doc.hasKeyword(x_holder.o_keywords[i]))
					{
						x_sum++;
					}
				}
				if (x_sum == 0)
				{
					x_false_matches++;
				}
			}
			x_holder.o_stats[POSSIBLE_TARGETS] -= x_false_matches;

			if (x_holder.o_depth > 0)
				// not sure about this - takes care of no local search at start ...
			{
				if (x_holder.o_depth < x_holder.o_TTL)
					// && x_holder.o_found == false)  
				{
					x_holder.o_stats[NO_MATCHES] += x_set.size();

					// check if the docs realy do have the search keywords

					x_holder.o_stats[NO_FALSE_MATCHES] += x_false_matches;
				}

				x_holder.o_found = true;

				if (x_holder.o_stats[TTL_FIRST_MATCH] == -1)
				{
					System.out.println(
						"first match: "
							+ x_holder.o_node.getNodeID()
							+ ", x_holder.o_TTL - x_holder.o_depth = "
							+ (x_holder.o_TTL - x_holder.o_depth));
					x_holder.o_stats[TTL_FIRST_MATCH] =
						x_holder.o_TTL - x_holder.o_depth;
				}
			}
		}
		System.out.println(
			"x_stats[ACTIVATED_NODES]: " + x_holder.o_stats[ACTIVATED_NODES]);
		System.out.println(
			"x_stats[POSSIBLE_TARGETS]: " + x_holder.o_stats[POSSIBLE_TARGETS]);
		System.out.println(
			"x_stats[MESSAGE_TRANSFERS]: "
				+ x_holder.o_stats[MESSAGE_TRANSFERS]);
		System.out.println(
			"x_stats[TTL_FIRST_MATCH]: " + x_holder.o_stats[TTL_FIRST_MATCH]);
		System.out.println(
			"x_stats[NO_MATCHES]: " + x_holder.o_stats[NO_MATCHES]);
		System.out.println(
			"x_stats[NO_FALSE_MATCHES]: " + x_holder.o_stats[NO_FALSE_MATCHES]);

		Node x_conn = null;

		Collection x_coll = x_holder.o_node.getConnList().values();
		x_coll.remove(x_holder.o_transmitter);
		// avoid checking the node we received from ...
		System.out.println("removing: " + x_holder.o_transmitter.getNodeID());

		Iterator x_conn_iter = x_coll.iterator();

		while (x_conn_iter.hasNext())
		{
			x_conn = (Node) (x_conn_iter.next());
			x_holder.o_unchecked_nodes.addFirst(
				new SearchHolder(
					x_conn,
					x_holder.o_node,
					x_holder.o_doc,
					x_holder.o_keywords,
					x_holder.o_depth + 1,
					x_holder.o_TTL,
					x_holder.o_stats,
					x_holder.o_nodes,
					x_holder.o_documents,
					x_holder.o_found,
					x_holder.o_unchecked_nodes));
		}
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testCreateDocuments() throws Exception
	{
		final int x_no_keywords = 5;
		final int x_no_docs = 5;
		final int x_no_keywords_per_doc = 3;

		// so far I have only looked at creating uniform and zipf distribution of keywords over documents
		// in a zipf distribution we give over control of how many documents we have, but in a uniform 
		// distribution we can specify a certain amount of keywords to create different effects ...

		adversarialnetwork.createKeywords(x_no_keywords);

		// feels like we should be specifying the type of distribution through an argument rather than
		// a global variable
		// also feels like we should be handing back a set of documents to check ....

		HashMap x_docs =
			adversarialnetwork.createDocuments(
				x_no_docs,
				x_no_keywords_per_doc,
				false,
				new Random());

		assertTrue("Wrong Number of docs", x_docs.size() == x_no_docs);
		Iterator x_iter = x_docs.values().iterator();
		Document x_doc = null;
		while (x_iter.hasNext())
		{
			x_doc = (Document) (x_iter.next());
			assertTrue(
				"Wrong number of keywords per doc",
				x_doc.getKeywords().length == x_no_keywords_per_doc);
			for (int j = 0; j < x_no_keywords_per_doc; j++)
			{
				assertTrue(
					x_doc.getKeywords()[j].getClass().getName().equals(
						"com.neurogrid.simulation.SimpleKeyword"));
			}
		}

		// JUnitDoclet end method createDocuments
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGenerateContent() throws Exception
	{
		final int x_no_nodes = 5;
		final int x_no_documents_per_node = 3;

		HashMap x_map =
			adversarialnetwork.createNodes(
				x_no_nodes,
				x_no_nodes,
				new Random(RANDOM_SEED));
		adversarialnetwork.generateContent(
			x_map,
			Document.o_documents,
			Document.o_document_ids,
			x_no_documents_per_node,
			false,
			new Random());
		Node x_node = null;

		Iterator x_iter = x_map.values().iterator();
		while (x_iter.hasNext())
		{
			x_node = (Node) (x_iter.next());
			assertTrue(x_node.getNoContents() == x_no_documents_per_node);
			for (int j = 0; j < x_no_documents_per_node; j++)
			{
				assertTrue(
					x_node
						.getContentsByDocID()
						.values()
						.toArray()[j]
						.getClass()
						.getName()
						.equals(
						"com.neurogrid.simulation.SimpleDocument"));
			}
		}

		// JUnitDoclet end method generateContent
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGenerateConnections() throws Exception
	{
		// JUnitDoclet begin method generateConnections

		// JUnitDoclet end method generateConnections
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGenerateRingTopology() throws Exception
	{
		// JUnitDoclet begin method generateRingTopology

		final int x_no_nodes = 5;
		final int x_no_conns = 2;

		HashMap x_map =
			adversarialnetwork.createNodes(
				x_no_nodes,
				x_no_nodes,
				new Random(RANDOM_SEED));
		Vector x_vec = Node.getVectorFromMap(x_map);
		adversarialnetwork.generateRingTopology(x_vec, x_no_conns);

		Node x_previous_node = null;
		Node x_node = null;
		Node x_next_node = null;

		for (int i = 0; i < x_no_nodes; i++)
		{
			// maybe this should be calling a getNode(Node p_node) method ...? //FIXXXXXXXXXX
			x_previous_node =
				(Node) (adversarialnetwork
					.getNodes()
					.get(x_vec.elementAt((i - 1 + x_no_nodes) % x_no_nodes)));
			x_node =
				(Node) (adversarialnetwork.getNodes().get(x_vec.elementAt(i)));
			x_next_node =
				(Node) (adversarialnetwork
					.getNodes()
					.get(x_vec.elementAt((i + 1) % x_no_nodes)));
			assertTrue(
				"no connection to previous node",
				x_node.hasConnection(x_previous_node));
			assertTrue(
				"no connection to next node",
				x_node.hasConnection(x_next_node));
		}

		final int x_new_no_nodes = 10;
		final int x_new_no_conns = 4;

		x_map =
			adversarialnetwork.createNodes(
				x_new_no_nodes,
				x_new_no_nodes,
				new Random(RANDOM_SEED));
		x_vec = Node.getVectorFromMap(x_map);
		adversarialnetwork.generateRingTopology(x_vec, x_new_no_conns);

		Node x_previous_previous_node = null;
		x_previous_node = null;
		x_node = null;
		x_next_node = null;
		Node x_next_next_node = null;

		for (int i = 0; i < x_new_no_nodes; i++)
		{
			// maybe this should be calling a getNode(Node p_node) method ...? //FIXXXXXXXXXX
			x_previous_node =
				(Node) (adversarialnetwork
					.getNodes()
					.get(
						x_vec.elementAt(
							(i - 1 + x_no_nodes) % x_new_no_nodes)));
			x_previous_previous_node =
				(Node) (adversarialnetwork
					.getNodes()
					.get(
						x_vec.elementAt(
							(i - 2 + x_no_nodes) % x_new_no_nodes)));
			x_node =
				(Node) (adversarialnetwork.getNodes().get(x_vec.elementAt(i)));
			x_next_node =
				(Node) (adversarialnetwork
					.getNodes()
					.get(x_vec.elementAt((i + 1) % x_new_no_nodes)));
			x_next_next_node =
				(Node) (adversarialnetwork
					.getNodes()
					.get(x_vec.elementAt((i + 2) % x_new_no_nodes)));
			assertTrue(
				"no connection to previous previous node",
				x_node.hasConnection(x_previous_previous_node));
			assertTrue(
				"no connection to previous node",
				x_node.hasConnection(x_previous_node));
			assertTrue(
				"no connection to next node",
				x_node.hasConnection(x_next_node));
			assertTrue(
				"no connection to next next node",
				x_node.hasConnection(x_next_next_node));
		}

		// JUnitDoclet end method generateRingTopology
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGenerateRandomTopology() throws Exception
	{
		// JUnitDoclet begin method generateRingTopology

		final int x_no_nodes = 5;
		final int x_no_conns = 2;

		HashMap x_map =
			adversarialnetwork.createNodes(
				x_no_nodes,
				x_no_nodes,
				new Random(RANDOM_SEED));
		Vector x_vec = Node.getVectorFromMap(x_map);
		adversarialnetwork.generateRandomTopology(
			x_vec,
			x_vec,
			x_no_conns,
			false);
		// should be testing higher degrees of connectivity ....FIXXXXXXXXX
		// should be testing reciprocal connection making ... FIXXXXXXXXXXXXX

		Node x_previous_node = null;
		Node x_node = null;
		Node x_next_node = null;

		for (int i = 0; i < x_no_nodes; i++)
		{
			x_node =
				(Node) (adversarialnetwork.getNodes().get(x_vec.elementAt(i)));
			assertTrue(
				"more than 2 connections per node, i.e. "
					+ x_node.getNoConnections(),
				x_node.getNoConnections() == x_no_conns);
			for (int j = 0; j < x_no_conns; j++)
			{
				assertTrue(
					"Connection not to specified set of nodes",
					x_map.containsKey(
						x_node.getConnList().keySet().toArray()[j]));
			}
		}

		final int x_new_no_nodes = 10;
		final int x_new_no_conns = 3;

		x_map =
			adversarialnetwork.createNodes(
				x_new_no_nodes,
				x_new_no_nodes,
				new Random(RANDOM_SEED));
		x_vec = Node.getVectorFromMap(x_map);
		adversarialnetwork.generateRandomTopology(
			x_vec,
			x_vec,
			x_new_no_conns,
			true);
		// should be testing higher degrees of connectivity ....FIXXXXXXXXX
		// should be testing reciprocal connection making ... FIXXXXXXXXXXXXX

		x_previous_node = null;
		x_node = null;
		x_next_node = null;

		for (int i = 0; i < x_new_no_nodes; i++)
		{
			x_node =
				(Node) (adversarialnetwork.getNodes().get(x_vec.elementAt(i)));
			// not sure what the real limit is on connectivity when we make connections reciprocal ...
			//System.out.println(x_node.getNoConnections());
			//assertTrue("more than 2 connections per node, i.e. "+x_node.getNoConnections(),
			//           x_node.getNoConnections() == 2);
			for (int j = 0; j < x_new_no_conns; j++)
			{
				assertTrue(
					"Connection not to specified set of nodes",
					x_map.containsKey(
						x_node.getConnList().keySet().toArray()[j]));
			}
		}

		// JUnitDoclet end method generateRingTopology
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGenerateTwoWayConnections() throws Exception
	{
		// JUnitDoclet begin method generateTwoWayConnections
		// JUnitDoclet end method generateTwoWayConnections
	}

	/**
	 * @throws Exception a general exception
	 */
	public void testGetUniformDistribution() throws Exception
	{
		final int x_no_keywords = 5;

		// need to make sure there are actually some keywords
		adversarialnetwork.createKeywords(x_no_keywords);
		final int x_no_bins = 5;
		final int x_no_items_per_bin = 3;
		HashMap x_item_table = Keyword.o_keywords;
		HashMap x_item_id_table = Keyword.o_keywords;

		// dist works over all the keywords - not just the ones we create here ...
		// other approaches could involve fixing the number of each keyword present
		// in advance, to remove random factor ...

		Object[][] x_dist =
			adversarialnetwork.getUniformDistribution(
				x_no_bins,
				x_no_items_per_bin,
				x_item_table,
				x_item_id_table,
				new Random());

		// definitely some sort of problem here since all documents 
		// are coming back with the same keywords - FIXXXXXXXXXXXXXXXX
		// need to create a test that will sort this ...           

		// would be good to be fixing random seeds so we can replicate ...              

		assertTrue(x_dist.length == x_no_bins);
		int k = 0;
		for (int i = 0; i < x_no_bins; i++)
		{
			assertTrue(x_dist[i].length == x_no_items_per_bin);
			for (int j = 0; j < x_no_items_per_bin; j++)
			{
				if (x_dist[i][j] == x_dist[(i + 1) % x_no_bins][j])
				{
					k++;
				}

				//	assertTrue("Same keyword in same place x_dist["+i+"]["+j+"]:" + 
				//	           x_dist[i][j] + " != x_dist["+(i+1)%x_no_bins+"]["+j+"]:"+ x_dist[(i+1)%x_no_bins][j],
				//	           x_dist[i][j] != x_dist[(i+1)%x_no_bins][j]);
				assertTrue(
					"Items not SimpleKeywords",
					x_dist[i][j].getClass().getName().equals(
						"com.neurogrid.simulation.SimpleKeyword"));
				System.out.print(x_dist[i][j] + " ");
			}
			System.out.println();
		}

		assertTrue(
			"Suspiciously high number of similar items",
			k < (x_no_bins * x_no_items_per_bin / 2));

		// not sure how to write a test that wil check the distribution
		// I guess we need some kind of metric such as the number of times that each 
		// item occurs - even then randomness could cause a test to fail ...
		// I guess we would have to run something many many times and then 
		// we woudl get an assessment of the effective randomness etc ...

		// JUnitDoclet end method getUniformDistribution
	}

	/**
	 * @throws Exception  a general exception
	 */
	public void testGetZipfDistribution() throws Exception
	{
		// JUnitDoclet begin method getZipfDistribution
		// JUnitDoclet end method getZipfDistribution
	}

	/**
	* JUnitDoclet moves marker to this method, if there is not match
	* for them in the regenerated code and if the marker is not empty.
	* This way, no test gets lost when regenerating after renaming.
	* Method testVault is supposed to be empty.
    * @throws Exception  a general exception
	*/
	public void testVault() throws Exception
	{
		// JUnitDoclet begin method testcase.testVault
		// JUnitDoclet end method testcase.testVault
	}

	/**
	 * @param args incoming arguments
	 */
	public static void main(String[] args)
	{
		// JUnitDoclet begin method testcase.main
		String x_method = System.getProperty("test.method");
		System.out.println("test.method=" + x_method);
		if (x_method == null || x_method.equals(""))
		{
			System.out.println("testing all methods");

			junit.textui.TestRunner.run(AdversarialNetworkTest.class);
		}
		else
		{
			System.out.println("testing single method");

			TestSuite suite = new TestSuite();
			suite.addTest(new AdversarialNetworkTest(x_method));
			junit.textui.TestRunner.run(suite);
		}
		// JUnitDoclet end method testcase.main
	}

}
